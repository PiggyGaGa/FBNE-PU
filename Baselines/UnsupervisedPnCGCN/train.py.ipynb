{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import pyhocon\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.TAXDataCenter import TAXDataCenter\n",
    "from src.utils import evaluate, train_classification, apply_model, get_gnn_TAXembeddings, test\n",
    "from src.models import GraphSage, Classification, UnsupervisedLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataSet', type=str, default='TaxH', choices=['TaxH', 'TaxZ', 'TaxS'])\n",
    "parser.add_argument('--agg_func', type=str, default='MEAN', choices=['MEAN', 'MAX'])\n",
    "parser.add_argument('--epochs', type=int, default=50)\n",
    "parser.add_argument('--b_sz', type=int, default=20)\n",
    "parser.add_argument('--seed', type=int, default=824)\n",
    "parser.add_argument('--cuda', action='store_true',help='use CUDA')\n",
    "parser.add_argument('--gcn', action='store_true')\n",
    "parser.add_argument('--learn_method', type=str, default='unsup', choices=['sup', 'unsup', 'plus_unsup'], help='sup： supervised learning, unsup: unsupervised learing, plus_unsup: supervised learning plus unsupervised loss')\n",
    "parser.add_argument('--unsup_loss', type=str, default='normal', choices=['normal', 'margin'])\n",
    "parser.add_argument('--max_vali_f1', type=float, default=0)\n",
    "parser.add_argument('--name', type=str, default='debug')\n",
    "parser.add_argument('--config', type=str, default='./src/taxConfig.conf')\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "\tif not args.cuda:\n",
    "\t\tprint(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\telse:\n",
    "\t\tdevice_id = torch.cuda.current_device()\n",
    "\t\tprint('using device', device_id, torch.cuda.get_device_name(device_id))\n",
    "\n",
    "device = torch.device(\"cuda:1\" if args.cuda else \"cpu\")\n",
    "print('DEVICE:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# # load config file\n",
    "config = pyhocon.ConfigFactory.parse_file(args.config)\n",
    "\n",
    "# load data\n",
    "ds = args.dataSet\n",
    "\n",
    "basic_feature = '/home/dada/TAX/TYC/ValidDATA/BasicFeature/{}_normalize.pickle'.format(ds)\n",
    "label_file = '/home/dada/TAX/TYC/ValidDATA/Label/{}_label.pickle'.format(ds)\n",
    "edges_file = '/home/dada/TAX/TYC/ValidDATA/NetworkEdges/{}_edges.pickle'.format(ds)\n",
    "\n",
    "dataCenter = TAXDataCenter(basic_feature, edges_file, label_file)\n",
    "dataCenter.load_dataSet(dataSet=ds)\n",
    "features = torch.FloatTensor(getattr(dataCenter, ds+'_feats')).to(device)\n",
    "\n",
    "graphSage = GraphSage(config['setting.num_layers'], features.size(1), config['setting.hidden_emb_size'], features, getattr(dataCenter, ds+'_adj_lists'), device, gcn=args.gcn, agg_func=args.agg_func)\n",
    "graphSage.to(device)\n",
    "\n",
    "num_labels = len(set(getattr(dataCenter, ds+'_labels')))\n",
    "classification = Classification(config['setting.hidden_emb_size'], num_labels)\n",
    "classification.to(device)\n",
    "\n",
    "unsupervised_loss = UnsupervisedLoss(getattr(dataCenter, ds+'_adj_lists'), getattr(dataCenter, ds+'_train'), device)\n",
    "\n",
    "if args.learn_method == 'sup':\n",
    "    print('GraphSage with Supervised Learning')\n",
    "elif args.learn_method == 'plus_unsup':\n",
    "    print('GraphSage with Supervised Learning plus Net Unsupervised Learning')\n",
    "else:\n",
    "    print('GraphSage with Net Unsupervised Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.learn_method == 'unsup':   ## unsupervised 训练\n",
    "    for epoch in range(args.epochs):\n",
    "        graphSage, _ = apply_model(dataCenter, ds, graphSage, classification, unsupervised_loss, args.b_sz, args.unsup_loss, device, args.learn_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, nsrdzdah = get_gnn_TAXembeddings(graphSage, dataCenter, ds)\n",
    "embeds = pd.DataFrame(embeddings)\n",
    "embeds.index = nsrdzdah\n",
    "embeddings_fin = embeds.loc[getattr(dataCenter, ds+'_node_names'), :]\n",
    "embeddings_fin.to_pickle('Embeddings{}_unsup_embeddings.pickle'.format(ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beike",
   "language": "python",
   "name": "beike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}